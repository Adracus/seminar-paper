\chapter{Summary}

The primary target of creating a service which securely hosts and shares
secrets has been achieved: The duse api and the command line client have
been released in a preview version. The duse webapp cannot currently be
released due to huge issues of the frontend language concerning cross
compilation as mentioned earlier. Some workarounds will be tried here,
closer details in the section future work.

The whole source code is hosted open source on github.com/duse-io.
In all repositories together, there are approximately 16k lines of code in
800 commits. This is distributed among 11 individual repositories:

\paragraph{api} This repository contains the backend implementation of
duse. It's dockerized and it depends on a database.

\paragraph{duse.rb} This contains a command line interface for accessing
a remote duse-api server. It can be used interactive as well as automatic.

\paragraph{duseapp} This is the webapp for the duse system. It can be
setup independently of a duse api server and only needs to point to an
api server address. As the issues regarding cross compilation and other
compatibility issues still prevail, it is currently not ready for deployment.

\paragraph{duse-dart} An abstract implementation of the duse client interface
for both server-side and client-side use.

\paragraph{secret\_sharing\_ruby} The secret sharing implementation for the
ruby programming language.

\paragraph{secret-sharing-dart} The secret sharing implementation fo the
dart programming language.

\paragraph{setup} A detailed description on how to setup one's own duse
instance.

\paragraph{rsa} An implementation of RSA for the dart programming language.

\paragraph{dart-coveralls} An interface implementation for the coveralls
coverage analysis service for coverage information generated by dart tests.

\paragraph{bbs} Implementation of the Blum-Blum-Shub random number generator
for the dart programming language.

\paragraph{lib-integration-tests} Rudimentary implementation of integration
tests between the dart and ruby implementations of the secret sharing algorithm.

\chapter{Future work}

While a working in most cases secure system has been designed in theory and
practise, there are still countless features to improve the system in terms of
features, security, and user experience.

\section{Primes with Miller Rabin}

In the current implementation of Duse, Mersenne primes are used to
compute in finite fields. They are easy to compute and there are
plenty of numbers lower than the used ones. An issue which results
of the Mersenne Primes is the predictability of the prime number
which is used for encryption. Also, encryption is limited to secrets
which are smaller than the largest prime number. If one wants to
get a larger prime number than the largest mersenne prime number the
computation time rises drastically. This is because all numbers
$< \sqrt{n}$ (where $n$ is an uneven number being tested) have to be evaluated
as possible dividers of $n$. If $n$ is not a prime, $n+1$ has to be
tested until a prime number is found. The computation time can be
decreased by applying a special version of the Sieve of Erathostenes but
it is still way too high. This is where the \textit{Miller-Rabin Test}
comes in. The Miller-Rabin Test is a Monte-Carlo algorithm. If one inputs
a number $n$, the tests has two possible results: It either returns
that $n$ is not a prime number or that $n$ is propably a prime number.
Internally, the test consist of congruency characteristics of prime numbers.
The test can be repeated and the propability of a number not being a
prime being accepted as prime is $\frac{1}{4^s}$, where s is the number
of iterations of the Miller-Rabin Test.

Although it is not as secure as exact computation, the Miller-Rabin Test
is also used in the RSA internals to get high prime numbers for the
private- and public key generation. RSA is considered as a secure
encryption scheme (also with secure paddings etc.) and if such a tested
software can rely on prime numbers generated by using the miller rabin
algorithm, Duse can too.

\section{Revisioning the data}

Being a security relevant system, duse should be thoroughbly auditable and be
able to perform rollbacks on user command. Therefore revisioning all the data
in the database should be added. Using a revisioning system it is
comprehensible, who did which changes and rollback to earlier versions if
required. There are ready to use libraries to add versioning to the database,
but there are still difficulties in how rollbacks can effect the overall
system. It would be required to recover older versions of specific rows, not
only the entire database.

A rollback would restore the exact state of the version rolled back to,
therefore also the participants having access to the secret. This also restores
the associated shares, which can turn into a problem. If the user is able to
change its public key as described in \ref{sec:update_key_pair}, the shares
restored can possibly not be decrypted by the user anymore, since the private
key has been removed. Furthermore, signatures would become invalid without also
rolling back the associated users to the same state, when checking signatures
client-side as described in \ref{sec:future:client_sig_check}. Without a
possibility to also achieve these features, revisioning is not worth it. The
other two features are too security relevant. The auditing part of revisions
might be done by logging all actions, that way it is at least possible to track
changes for a secret, without rollbacks. (see \ref{sec:event_logging} for more
information)

\section{Private key sharing}

In today's world, a single user often has several devices and wants to access
secrets from each device. To do so, the public key is needed to be synced for
encryption and the private key for decryption. While the public key is no
sensitive information (it can be shared freely, it is only important for others
to know if it belongs to the correct person) the private key is highly sensitive
data: If it is disclosed inadvertently, unauthorized people are able to decrypt
each information which was encrypted with the corresponding public key. Therefore,
to sync a private key across several devices, a secure mechanism has to be
established.

A company called \textit{Whiteout}, which focuses on cryptographically secure
emails, made a proposal addressing this issue \cite{whiteout_pgp_sync}. It
suggests that users can encrypt and upload their private key using a symmetric
cipher, generating a sequence called \textit{keychain code} as the key.
If now a new device wants to have the private key, the user first has to enter
a device key which is obtained through, for example, a short message sent by
whiteout. If the device key is correct, the user has to enter the keychain code
in order to download and encrypt the private key for use on the device.
This principle of sharing the private key could also be a conceivable solution
for duse in the future.

\section{Offline access}

Whenever a secret is retrieved, saved, updated, or deleted, it is performed by
HTTP calls to the RESTful API. If the user is not able to access the API, none
of these actions are possible. An offline access can be helpful to do so, however,
also brings new challenges with it.

\subsection{Conflicts}

Performing actions on an offline storage is difficult, as the cryptographic
protocol highly depends on the access to the API. If the API is not accessible,
creating new secrets, deleting and updating secrets becomes impossible if
attemped in an offline environment. Retrieving secrets can be done once and be
kept in an encrypted offline storage, which can be encrypted with a key.

To be able to create new secrets and delete secrets, a local change log can be
recorded, whenever the user performs an action, which the constraint, that the
secret cannot be shared, since the user profiles and thus their public keys are
not accessible. When the user has acess to the API again, then the change set
can be applied to the live system having regard to conflicts. While the user
was performing actions on the local secrets, there could be conflicts with
actions other users have been doing to the live system.

By restricting actions to perform in offline mode to retrieving secrets,
deleting secrets for all secrets and creating and updating secrets owned only
by the user these conflicts can be avoided.

Otherwise mergestrategies have to be developed, which can only be client-side,
since the server has no knowledge of the encrypted content.

\subsection{Unrestricted access complications}
\label{sub_sec:unrestricted_access}

A core functionality is revoking the access to a secret for users. Having
offline usage would counteract against this mechanism as revoking the secret by
denying access in the API does not detain access to the local, offline storage.

However, due to the nature of the developed cryptographic protocol, any client
developed by a third party could implement such a feature, therefore, it is
good to think about safe solutions beforehand.

\section{Groups}

When sharing secrets, it conceivable that a group of secrets are commonly
shared with the same participants. This involves a more complex strategy of
permissions and grouping secrets logically together. Inside a group creation
rights are can be limited and only specific persons inside a group could for
example have the authority to update and delete secrets.

When a member of a group is removed, all access to the shares is denied. It
could also work similarly to leasing secrets as described later in
\ref{sec:leasing_secrets}.

Aside from access to secrets, the group would also need to be managed in regard
to rights to add or remove users. Due to the nature of the cryptographic
protocol, this would also require all owners of a group to also be owners of
the secrets belonging to the group, since adding and removing users requires
decrypting the secret. However this constraint is reasonable anyways.

\section{Advanced permissions}

Currently, duse supports all CRUD operations regarding secrets. However,
sometimes this isn't the desired behaviour: If one user created a secret,
he or she might want others to read it but not modify it. Therefore, an
advanced permission system should be established: It should be possible to
control reads, updates and deletions for each secret. Additionally, if
someone is in a group, it might be good if one could control who creates
secrets for the group or not.

\subsection{Sub-Users}

Sub-Users are also an additional functionality duse wants to introduce in
the future which tackles problems during using duse for server provisioning:
If a provisioned server needs access to some duse configuration parameters,
for example as ENV-variables, how could one establish access for that server
to the duse ecosystem? One option would be to create a new user and to make
this user shareholder of the needed secrets. This would in fact work but for
each provisioned server there would be an additional user which would be a
huge overhead and difficult to maintain. That's why so called Sub-Users should
be introduced: Sub-Users are nothing more than a token authorized by a certain
user and it gives access to reading all secrets that user can read with the
user's permissions. One could also think of a permission system with finer
granularity here (for example, Sub-User groups and token-specific permissions)
but primarily the token function should be established.

\subsection{Fully using Shamir's Secret Sharing}

The current implementation of duse features secrets with a default and 
immutable threshold of 2. This means that always two users are needed in
order to restore a secret (of which one is always the server). The original
idea of secret sharing is the freely choosen threshold $\geq 2$, which
means that it is also possible to create a secret which needs two or more
shareholders in order to unlock it. For example, if there were three users
needed (user A, user B and the Server), it would not be sufficient just to
wait for the decrypted share of the server for user a or user b to decrypt
the secret. The users would also need the ``approval'' of the other user
in form of their decrypted share to unlock the secret. At runtime, this could
also differ if for example there were five users and the secret's threshold
is three: One user of these four users (the fifth one is the server) would
need the server share and one share of the remaining three users, regardless
which of these three users approves with his share.

A concept to make this possible could be queues: If one wanted
approval for a secret, one could demand approval from the other needed
shareholders. The other shareholders can then ``approve'' and send their
shares to the queue of the demanding user, who was waiting for these shares
to decrypt the secret.

\subsection{Leasing secrets}
\label{sec:leasing_secrets}

It is thinkable, that a secret should be accessible by another user for a
specific timespan. It would only require the owner to create another share for
the user and make it available via the API. The API can then delete this share
once the timespan has ended without any other interaction by the owner,
therefore removing access from the user the lease was issued to.

Very similar to offline access, as described in
\ref{sub_sec:unrestricted_access}, the problem is, that the user could have
decrypted the secret during the timespan and saved it in another way. The user
issueing the lease could possibly be warned of such situations. The
\textit{mark as insecure} feature as described in \ref{sec:mark_as_insecure}
could be used to achieve this, depending on the security level of the secret.

\section{Event logging}
\label{sec:event_logging}

The CIA triad confidentiality, integrity and availability are the core
concepts of information security. Non-repudation was often considered
to be added but conflicted with the idea of the core iddea of information
security. Nevertheless, non-repudation plays an important role for the
future of the duse system: It should be possible to know who accessed
which secret when, how often and using which client. This all makes it
possible to get a more detailed view of user activity and also enables
administrators of duse systems to identify possible security leaks.

Event logging for duse has to be ubiquitous, every action has to be
logged and comprehensible. Because duse is a security critical system
and the secrets themselves are not decryptable even from the duse API
itself this won't conflict with the privacy of users.

The main sections of logging are:
\begin{itemize}
  \item Request control: Each request (also from anonymous sources) have
  to be logged. People could try to DDoS or use vulnerabilities of the
  duse system. Admins should be informed if there are anomalies in order
  to establish countermeasures.

  \item Secret access: Secret access is a very important point of logging:
  Who accesssed a secret and when? This coul be of interest for example if
  a private key of a person has been unveilled, did this person access any
  secrets after that point in time?

  \item Organisational access: Public keys of users are an insurance that
  only authorized persons can read shares. Access to these is therefore
  also crucial and has to be logged.
\end{itemize}

Using event logging in conjunction with revisioning data in the database allows
revisions and the event together to form named rollbacks, which would be far
more descriptive than rolling back to a specific revision number.

\section{RSA OAEP}

The PKCS\#1v1.5 padding scheme is not considered secure since
\textit{Bleichenbacher's CRYPTO 98 Paper} \cite{rsabulletin}
revealed a chosen ciphertext attack \footnote{
  An attacker is able to decrypt self-chosen ciphertexts (also
  known as Decryption Oracle). \cite[p. 70]{baumann2014kryptographische}
}.
It is still used inside TLS encryption at the time of writing,
but just because TLS does it doesn't make it right. A very important
future work is to replace the default PKCS\#1v1.5 padding scheme with
the more secure OAEP padding scheme.

The Optimal Asymmetric Encryption Padding or also \textit{OAEP}
is an algorithm which is a form of a \textit{Feistel Network}\footnote{
  Feistel Networks or Feistel Ciphers are symmetric structures which are used
  during the construction of block ciphers with the most prominent example
  being the DES encryption. In general, a Feistel cipher is a cipher which
  iteratively applies an internal function, often referred as \textit{round function}.
}. OAEP prevents information leakage caused by partial decryption of 
ciphertexts and also turns deterministic encryption schemes like RSA into
propabilistic encryption schemes. When used with RSA, OAEP is called
RSA-OAEP.

\subsection{Applying the padding}

To pad a message $m$ of length $k$ bits, one first has to choose a sequence
$r$ of $k_0$ randomly generated bits. Then one calculates

$$X = m \oplus G(r)$$

and

$$Y = r \oplus H(m \oplus G(r))$$

with $G$ and $H$ being cryptographic hash functions. To then compute the
ciphertext $c$, one finally calculates the trap door function $f$ of the
concatenation of $X$ and $Y$

$$c = f(X || Y)$$

\subsection{Striping the Padding}

In order to get $X$ and $Y$ out of $c$, one first has to unapply the
trapdoorfunction $f$.

$$X || Y = f^{-1}(c)$$

$r$ can then be reconstructed by calculating

$r = Y \oplus H(x)$

With $r$ one can finally get the original message $m$ by applying XOR
to the padding part $X$ with $G(r)$:

$$m = X \oplus G(r)$$

\section{Key establishment}
\label{sec:key_establishment}

If one wants to share his secret with many others, one first encrypts the
secret into many shares with the secret sharing scheme. After that, one needs
to fetch all public keys of the secret's participants in order to encrypt the
shares so no unauthorized person has access to the share. In the current
implementation of Duse, the public keys are stored as part of a user account
in the Duse system. But the Duse system itself is \textit{not} designed to
work as a public key exchange. If it is compromised, the public key access
becomes a major attack point: A fake public key could be downloaded and shares
could be encrypted with an insecure public key. As a result, an attacker
could easily read shares without permission, if he has access to the database
or the entire Duse system. Duse is not the right place to perform public
key exchange. It is designed to host and distribute secrets to users with ease.
As mentioned before, secret exchange is still safe even if the server is compormised
but the area of public key exchange is one major attack point.
The key exchange should therefore be outsourced to another
infrastructure or happen between the users directly. There are three possible
solutions for this problem.

\subsection{Diffie-Hellman key exchange}

The Diffie-Hellman key exchange is one option. Users which want to share secrets
start the Diffie-Hellman key exchange as described in the section Cryptography
Fundamentals. But there are two main attack points here:

First, how can one user even know the IP-Address of the other user? If a compromised
Duse system hosts the address of each participant for the key exchange, one could
easily change the address so that the key exchange is made with the wrong person.

Even if this problem could be solved somehow (secret channels or manual IP transmission
between future share holders), the possibility of a man-in-the-middle attack still
exists. The attacker could easily redirect participant traffic so that all participants
actually exchange keys with the attacker than with their original target.
These insecurities as well as the huge workload each user has to do to obtain
secure IP addresses are the reason for not choosing the Diffie-Hellman key exchange
as the public key exchange protocol for Duse.

\subsection{Trust Models for Public Key Infrastructures}

To get the right public key, public key infrastructures or short \textit{PKI}s use
digital certificates. Digital certificates proof the authenticity of a key. To proof
the authenticity of such a digital signature, one can check the signature with the
public key of the signer. The authenticity of the signer itself can then be checked
by checking another digital signature. This builds up a chain of signatures and 
signers relying on each other and ends on a single certificate which has to be trusted.
Currently, there are several models of PKIs which are interesting for the use
in conjunction with duse.

\subsubsection{Strict Hierarchical PKI}

This PKI model relies on a root certification authority, short \textit{Root-CA}.
All other groups have to trust this Root-CA.
De facto a single Root-CA does not exist. There is a Root-CA for many countries
in order for them to be able to control their trust chain.
The certificate of this Root-CA, the
root certificate, has no signature and is therefore called \textit{self-signed}.
Products, like for example \textit{Google Chrome} or other main browsers are
shipped with some chosen, default trusted Root-CAs in order for the trust-chain
to work with the product. A disadvantage of this certification model is the
strong dependency on the Root-CA as well as the power the Root-CA possesses.
If one wants a trusted certificate nowadays, one has to pay a lot of money to
get one. This creates a strong conjunction of the amount of money someone has with
the trustworthyness that someone gets by obtaining an expensive, valuable certificate.

\subsubsection{Cross Certification}

Cross certification nearly has the same model of certification as the Strict
Hierarchical PKI with the difference being that there can be two or more
Root-CAs. Those independently working certification authorities mutually
sign their root certificates. This creates a sign of trust between the two
CAs. Today this is used as a method to connect two or more hierarchical PKIs
in order to achieve cross country communication. The disadvantage of this
technology is the amount of cross certificates between the several Root-CAs
which rises squarely with the number of Root-CAs.

\subsubsection{Web of Trust}

In the Web of Trust, each user can trust each other and sign their public keys.
The propability of a key belonging to a user rises with the amount of certificates
that user has received. Each user can also specify the so called owner trust on
a key of another person. The owner trust can be several levels from unknown to
not tusted to ultimate trust. If now one wants to trust another user, one can
calculate the \textit{key legitimacy} out of the number of certificates on that
key as well as the individual trust levels. The concept of the web of trust allows
control about who to trust or who not to trust. Therefore, the participants of
the web should be able to identify who to trust and they should be sophisticated
in terms of creating a trusted web.

\section{Client side signature checks}
\label{sec:future:client_sig_check}

Besides attacks with the goal of attaining a secret in plaintext, there is also
another type of attack, which is feasible for duse. A man in the middle
attacker could replace the shares with a secret, the attacker created, since
the public keys are also accessed for the procedure. This could be the goal of
the attacker, if attaining the plaintext is not necessary, but the resulting
secret the user receives is under complete control of the attacker.

To avoid such situations, the client could also check the signature of the
received shares, until now, only the server performs integrity checks by
verifying the signature at time of creation. Using a method of key
establishment, the clients can also ensure, the received public keys are not
tampered, or notice, when the they are tampered. (see
\ref{sec:key_establishment}) After the key exchange, the signatures can be
checked.

Since the signatures are generated every time a secrets content or the
participants the secret is shared with are modified, the system has to
remember, who modified them last. Therefore the API can tell the client which
users public key to use when verifying signatures of a specific secret.

\section{Updating key pairs}
\label{sec:update_key_pair}

It is possible, that in the lifetime of a key pair it will become insecure,
either by disclosure of the private key or by vulnerabilities in the underlying
implementations, such as the heartbleed bug. Incidents as described require
the replacement of the current key pair with a new benign key pair.

Replacing the key, however, requires multiple steps. All shares a user owns are
encrypted with the original public key. Therefore, the user must decrypt all
shares, and encrypt them with the new key, which poses another obstacle. While
a user decrypts and encrypts the shares with the new key, other users still
access the old key and create new shares encrypted with it.

Simultaneously updating the public key and the shares also does not work, as it
does not eliminate the possiblity of users creating new shares with the old key
before the newly encrypted shares replace the old ones..

To avoid this race condition, the key must be updated first and then the shares
have to be replaced in separate steps.

In conjunction with client side signature checks
\ref{sec:future:client_sig_check} the proposed solution is a dilemma as either
the shares get in a race condition or the public key to check the signature
with. Only one of the race conditions can be solved by without introducing
further mechanisms. Since the shares are a basic demand of the system to work,
and the signature checks only for additional security, restrictions on them are
less trouble. Otherwise it would require the update process to be finished,
before other users can access a secret. Instead when decrypting a secret, the
system could inform the user, that the signature currently cannot be verified
due to the key pair update in progress.

So before the client updates the shares, the key is replaced with the new one,
with a flag, that the key cannot be used for signature checks, yet. Once all
shares are updated, the flag can be removed.

It also requires the system to not only remember, who changed the secret in
whole, but also shares in detail.

Using multiple steps to update the key pair allow the user to leave the process
uncompleted. This circumstance also leaves the key pair as not to be used for
signature checks. Therefore the system should rollback the update process after
a specific timespan. Revisioning all the data would ease the rollback
immensely. (see \ref{sec:future:revisoning})

\section{Additional clients}

Duse offers a protocol which is independent of client programming languages.
Therefore, it is easy to implement clients based on different
languages. This leads to faster adoption of the duse technology stack by
other developers and this leads to contributions of the community as well
as a better reputation for duse. One could think of clients in several
popular programming languages such as Python, but the main focus of planned
clients is the availability of duse on lots of various platforms.
Planned are client implementations for the JVM as well as directly executable
machine code clients for various PC architectures. Additionally, a working
Javascript client should be established because of the cross compilation issue.

\subsection{Javascript client}

There are two approaches in implementing a Javascript client: The first
approach is by cross compiling the backend language into Javascript. There
is a well-maintained compiler for this purpose, but arbitrary size integers
have to be implemented there as well. The other approach is by writing
an entirely new client in vanilla Javascript. An advantage of a pure JS
client would be that the Javascript community has access to a clean
implementation of the duse technology stack.

\subsection{JVM-based client}

The JVM is available on lots of different architectures and offers a good 
abstraction on which many languages build. Some mentionable languages here are
of course Java, Scala and Clojure. These languages are bytecode compatible,
a single implementation here could be used across several JVM based languages.
As such, the JVM offers a broad developer community in which duse should
integrate in order for better adaption as well as a better availability of
clients. A difficulty of JVM based languages is the final packaging of the
executable software for different operating systems because of the dependency
on a specific JVM. Hence, a client in machine code should also exist.

\subsection{Machine code client}

Machine code clients have several advantages: They are easy to ship (compile
once per OS and underlying architecture) and usually performing rapidly.
Languages for this use case are for example C, Go, Rust and Nim.

\section{Mark as insecure}
\label{sec:mark_as_insecure}

Similar to private keys becoming insecure, so can secrets themselves. There
should be a way to inform other users, that a secret has become insecure. This
could either happen through a manual process or automatically through specific
event triggers.

Manually flagging a secret as insecure could be the result of the disclosure of
an individual secret.

An automated way of flagging secrets as insecure can simply be an expiry date.
Once the expiry date passes, the secret becomes insecure.

There could also be several security levels for secrets. A security level could
determine which events mark a secret as insecure. It is thinkable, that for
example whenever a participant's access is removed, the secret should becomes
insecure as the participant had the possibility to save the secret through
another channel.

\section{Hybrid encryption}

Hybrid encryption is known as the combination of asymmetric encryption and
symmentric encrypiton. First the plaintext is encrypted with a symmetric
encryption algorithm with a preferably randomly generated key. The used key is
then encrypted with the asymmetric public key algorithm. Hybrid encrypiton
eliminates some of the drawbacks for both kinds of algorithms.

For symmetric encryption the soundness relies on the randomness of the key
used. If the key is not random, then there is no point in using it. If the key,
however, is random and complex, then it is very well suited. The problem with
random and complex keys is, that they are hard to remember for humans.
Therefore the key is encrypted with the public key of a user, who can encrypt
it due to the ownership of the private key.

Not only does this have an effect on the usability for humans, but it also
softens restrictions of the two mechanisms. A restriction of asymmetric
encryption is the limited plaintext size. Symmetric encryption does not have
any limit on the plaintext size, and is significantly more performant.
Therefore combining the who algorithms allows these restrictions to be
eliminated.

Integrating hybrid encryption into the duse protocol would require the secret
to save to be encrypted with symmetric encryption using a randomly generated
key. The key is then divided using Shamir's Secret Sharing and each share is
then encrypted with the participating users public keys.

\subsection{Advantages}

Introducing hybrid encryption would improve multiple aspects of the overall
system. In the following paragraphs, the most notable ones are depicted.

\paragraph{Less asymmetric crypto}{ In comparison to the mechanism developed in
  \ref{sec:duse:crypto_protocol}, this only requires asymmetric encryption to
  be used once per user, instead of once per user per secret part. Additionally
  it allows large secrets to be saved more efficiently, since the decryption of
the symmetric cipher texts is very performant. Requireing thousands of
decryption processes is not feasible, in contrast to a single performant
decryption.}

\paragraph{Less complex storage}{ Not only does this mechanism reduce the load
  on clients, but also on the server. The server decrypts its own share of the
  symmetric key only once instead of $n$ times, where $n$ is the number of
  parts of a secret.  Having many parts, which in turn also have many shares is
complex to safe. A single large cipher text is easier to handle. If the upper
limits of a data type of the used database is not large enough, the cipher
texts could be safed in a distributed filesystem.}

\paragraph{Less complex, more efficient Validation}{ Besides the improved
  storage possibilities on a low level, the complexity of the associations is
  also reduced. Instead of each part containing shares, a secret only has one
  set of shares.  Therefore the semantic validation also becomes less complex,
  since relationships between parts do not have to be verified. When using the
  parts attempt, the server has to verify, that all users the shares assiociate
  to have to be the same for all parts. Apart from that, each shares signature
  is checked, which is a slow operation. An attacker could use this
characteristic to perform a denial of service attack. Using the hybrid
encryption approach minimizes the signature checks to the number of
participants. }

\paragraph{Detailed updates}{ Separating cipher and access allows updating a
  secret to be performed in a more detailed manner. The cipher text must only
  be modified, if the plaintext it conceals is changed. If the participating
  parties are modified only the shares are changed. Hence, the API can
differentiate what part of the secret is changed and can log the type of
change, as well as have named rollbacks when using a revisioning mechanism. }
