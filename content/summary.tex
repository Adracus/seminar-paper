\chapter{Summary}

Summary ...

\chapter{Future work}

While a working in most cases secure system has been designed in theory and
practise, there are still countless features to improve the system in terms of
features, security, and user experience.

\section{Primes with Miller Rabin}

In the current implementation of Duse, Mersenne primes are used to
compute in finite fields. They are easy to compute and there are
plenty of numbers lower than the used ones. An issue which results
of the Mersenne Primes is the predictability of the prime number
which is used for encryption. Also, encryption is limited to secrets
which are smaller than the largest prime number. If one wants to
get a larger prime number than the largest mersenne prime number the
computation time rises drastically. This is because all numbers
$< \sqrt{n}$ (where $n$ is an uneven number being tested) have to be evaluated
as possible dividers of $n$. If $n$ is not a prime, $n+1$ has to be
tested until a prime number is found. The computation time can be
decreased by applying a special version of the Sieve of Erathostenes but
it is still way too high. This is where the \textit{Miller-Rabin Test}
comes in. The Miller-Rabin Test is a Monte-Carlo algorithm. If one inputs
a number $n$, the tests has two possible results: It either returns
that $n$ is not a prime number or that $n$ is propably a prime number.
Internally, the test consist of congruency characteristics of prime numbers.
The test can be repeated and the propability of a number not being a
prime being accepted as prime is $\frac{1}{4^s}$, where s is the number
of iterations of the Miller-Rabin Test.

Although it is not as secure as exact computation, the Miller-Rabin Test
is also used in the RSA internals to get high prime numbers for the
private- and public key generation. RSA is considered as a secure
encryption scheme (also with secure paddings etc.) and if such a tested
software can rely on prime numbers generated by using the miller rabin
algorithm, Duse can too.

\section{Private key sharing}
\section{Groups}

\section{Event logging}

The CIA triad confidentiality, integrity and availability are the core
concepts of information security. Non-repudation was often considered
to be added but conflicted with the idea of the core iddea of information
security. Nevertheless, non-repudation plays an important role for the
future of the duse system: It should be possible to know who accessed
which secret when, how often and using which client. This all makes it
possible to get a more detailed view of user activity and also enables
administrators of duse systems to identify possible security leaks.

Event logging for duse has to be ubiquitous, every action has to be
logged and comprehensible. Because duse is a security critical system
and the secrets themselves are not decryptable even from the duse API
itself this won't conflict with the privacy of users.

The main sections of logging are:
\begin{itemize}
  \item Request control: Each request (also from anonymous sources) have
  to be logged. People could try to DDoS or use vulnerabilities of the
  duse system. Admins should be informed if there are anomalies in order
  to establish countermeasures.

  \item Secret access: Secret access is a very important point of logging:
  Who accesssed a secret and when? This coul be of interest for example if
  a private key of a person has been unveilled, did this person access any
  secrets after that point in time?

  \item Organisational access: Public keys of users are an insurance that
  only authorized persons can read shares. Access to these is therefore
  also crucial and has to be logged.
\end{itemize}

Using event logging in conjunction with revisioning data in the database allows
revisions and the event together to form named rollbacks, which would be far
more descriptive than rolling back to a specific revision number.

\section{Offline access}
\section{Advanced permissions}

\section{RSA OAEP}

The PKCS\#1v1.5 padding scheme is not considered secure since
\textit{Bleichenbacher's CRYPTO 98 Paper} \cite{rsabulletin}
revealed a chosen ciphertext attack \footnote{
  An attacker is able to decrypt self-chosen ciphertexts (also
  known as Decryption Oracle). \cite[p. 70]{baumann2014kryptographische}
}.
It is still used inside TLS encryption at the time of writing,
but just because TLS does it doesn't make it right. A very important
future work is to replace the default PKCS\#1v1.5 padding scheme with
the more secure OAEP padding scheme.

The Optimal Asymmetric Encryption Padding or also \textit{OAEP}
is an algorithm which is a form of a \textit{Feistel Network}\footnote{
  Feistel Networks or Feistel Ciphers are symmetric structures which are used
  during the construction of block ciphers with the most prominent example
  being the DES encryption. In general, a Feistel cipher is a cipher which
  iteratively applies an internal function, often referred as \textit{round function}.
}. OAEP prevents information leakage caused by partial decryption of 
ciphertexts and also turns deterministic encryption schemes like RSA into
propabilistic encryption schemes. When used with RSA, OAEP is called
RSA-OAEP.

\subsection{Applying the padding}

To pad a message $m$ of length $k$ bits, one first has to choose a sequence
$r$ of $k_0$ randomly generated bits. Then one calculates

$$X = m \oplus G(r)$$

and

$$Y = r \oplus H(m \oplus G(r))$$

with $G$ and $H$ being cryptographic hash functions. To then compute the
ciphertext $c$, one finally calculates the trap door function $f$ of the
concatenation of $X$ and $Y$

$$c = f(X || Y)$$

\subsection{Striping the Padding}

In order to get $X$ and $Y$ out of $c$, one first has to unapply the
trapdoorfunction $f$.

$$X || Y = f^{-1}(c)$$

$r$ can then be reconstructed by calculating

$r = Y \oplus H(x)$

With $r$ one can finally get the original message $m$ by applying XOR
to the padding part $X$ with $G(r)$:

$$m = X \oplus G(r)$$

\section{Key establishment}
\label{sec:key_establishment}

If one wants to share his secret with many others, one first encrypts the
secret into many shares with the secret sharing scheme. After that, one needs
to fetch all public keys of the secret's participants in order to encrypt the
shares so no unauthorized person has access to the share. In the current
implementation of Duse, the public keys are stored as part of a user account
in the Duse system. But the Duse system itself is \textit{not} designed to
work as a public key exchange. If it is compromised, the public key access
becomes a major attack point: A fake public key could be downloaded and shares
could be encrypted with an insecure public key. As a result, an attacker
could easily read shares without permission, if he has access to the database
or the entire Duse system. Duse is not the right place to perform public
key exchange. It is designed to host and distribute secrets to users with ease.
As mentioned before, secret exchange is still safe even if the server is compormised
but the area of public key exchange is one major attack point.
The key exchange should therefore be outsourced to another
infrastructure or happen between the users directly. There are three possible
solutions for this problem.

\subsection{Diffie-Hellman key exchange}

The Diffie-Hellman key exchange is one option. Users which want to share secrets
start the Diffie-Hellman key exchange as described in the section Cryptography
Fundamentals. But there are two main attack points here:

First, how can one user even know the IP-Address of the other user? If a compromised
Duse system hosts the address of each participant for the key exchange, one could
easily change the address so that the key exchange is made with the wrong person.

Even if this problem could be solved somehow (secret channels or manual IP transmission
between future share holders), the possibility of a man-in-the-middle attack still
exists. The attacker could easily redirect participant traffic so that all participants
actually exchange keys with the attacker than with their original target.
These insecurities as well as the huge workload each user has to do to obtain
secure IP addresses are the reason for not choosing the Diffie-Hellman key exchange
as the public key exchange protocol for Duse.

\subsection{Trust Models for Public Key Infrastructures}

To get the right public key, public key infrastructures or short \textit{PKI}s use
digital certificates. Digital certificates proof the authenticity of a key. To proof
the authenticity of such a digital signature, one can check the signature with the
public key of the signer. The authenticity of the signer itself can then be checked
by checking another digital signature. This builds up a chain of signatures and 
signers relying on each other and ends on a single certificate which has to be trusted.
Currently, there are several models of PKIs which are interesting for the use
in conjunction with duse.

\subsubsection{Strict Hierarchical PKI}

This PKI model relies on a root certification authority, short \textit{Root-CA}.
All other groups have to trust this Root-CA.
De facto a single Root-CA does not exist. There is a Root-CA for many countries
in order for them to be able to control their trust chain.
The certificate of this Root-CA, the
root certificate, has no signature and is therefore called \textit{self-signed}.
Products, like for example \textit{Google Chrome} or other main browsers are
shipped with some chosen, default trusted Root-CAs in order for the trust-chain
to work with the product. A disadvantage of this certification model is the
strong dependency on the Root-CA as well as the power the Root-CA possesses.
If one wants a trusted certificate nowadays, one has to pay a lot of money to
get one. This creates a strong conjunction of the amount of money someone has with
the trustworthyness that someone gets by obtaining an expensive, valuable certificate.

\subsubsection{Cross Certification}

Cross certification nearly has the same model of certification as the Strict
Hierarchical PKI with the difference being that there can be two or more
Root-CAs. Those independently working certification authorities mutually
sign their root certificates. This creates a sign of trust between the two
CAs. Today this is used as a method to connect two or more hierarchical PKIs
in order to achieve cross country communication. The disadvantage of this
technology is the amount of cross certificates between the several Root-CAs
which rises squarely with the number of Root-CAs.

\subsubsection{Web of Trust}

In the Web of Trust, each user can trust each other and sign their public keys.
The propability of a key belonging to a user rises with the amount of certificates
that user has received. Each user can also specify the so called owner trust on
a key of another person. The owner trust can be several levels from unknown to
not tusted to ultimate trust. If now one wants to trust another user, one can
calculate the \textit{key legitimacy} out of the number of certificates on that
key as well as the individual trust levels. The concept of the web of trust allows
control about who to trust or who not to trust. Therefore, the participants of
the web should be able to identify who to trust and they should be sophisticated
in terms of creating a trusted web.

\section{Client side signature checks}
\label{sec:future:client_sig_check}

Besides attacks with the goal of attaining a secret in plaintext, there is also
another type of attack, which is feasible for duse. A man in the middle
attacker could replace the shares with a secret, the attacker created, since
the public keys are also accessed for the procedure. This could be the goal of
the attacker, if attaining the plaintext is not necessary, but the resulting
secret the user receives is under complete control of the attacker.

To avoid such situations, the client could also check the signature of the
received shares, until now, only the server performs integrity checks by
verifying the signature at time of creation. Using a method of key
establishment, the clients can also ensure, the received public keys are not
tampered, or notice, when the they are tampered. (see
\ref{sec:key_establishment}) After the key exchange, the signatures can be
checked.

Since the signatures are generated every time a secrets content or the
participants the secret is shared with are modified, the system has to
remember, who modified them last. Therefore the API can tell the client which
users public key to use when verifying signatures of a specific secret.

\section{Updating key pairs}

It is possible, that in the lifetime of a key pair it will become insecure,
either by disclosure of the private key or by vulnerabilities in the underlying
implementations, such as the heartbleed bug. Incidents as described require
the replacement of the current key pair with a new benign key pair.

Replacing the key, however, requires multiple steps. All shares a user owns are
encrypted with the original public key. Therefore, the user must decrypt all
shares, and encrypt them with the new key, which poses another obstacle. While
a user decrypts and encrypts the shares with the new key, other users still
access the old key and create new shares encrypted with it.

Simultaneously updating the public key and the shares also does not work, as it
does not eliminate the possiblity of users creating new shares with the old key
before the newly encrypted shares replace the old ones..

To avoid this race condition, the key must be updated first and then the shares
have to be replaced in separate steps.

In conjunction with client side signature checks
\ref{sec:future:client_sig_check} the proposed solution is a dilemma as either
the shares get in a race condition or the public key to check the signature
with. Only one of the race conditions can be solved by without introducing
further mechanisms. Since the shares are a basic demand of the system to work,
and the signature checks only for additional security, restrictions on them are
less trouble. Otherwise it would require the update process to be finished,
before other users can access a secret. Instead when decrypting a secret, the
system could inform the user, that the signature currently cannot be verified
due to the key pair update in progress.

So before the client updates the shares, the key is replaced with the new one,
with a flag, that the key cannot be used for signature checks, yet. Once all
shares are updated, the flag can be removed.

It also requires the system to not only remember, who changed the secret in
whole, but also shares in detail.

Using multiple steps to update the key pair allow the user to leave the process
uncompleted. This circumstance also leaves the key pair as not to be used for
signature checks. Therefore the system should rollback the update process after
a specific timespan. Revisioning all the data would ease the rollback
immensely. (see \ref{sec:future:revisoning})

\section{Revisioning the data}

\section{Additional clients}

Duse offers a protocol which is independent of client programming languages.
Therefore, it is easy to implement clients based on different
languages. This leads to faster adoption of the duse technology stack by
other developers and this leads to contributions of the community as well
as a better reputation for duse. One could think of clients in several
popular programming languages such as Python, but the main focus of planned
clients is the availability of duse on lots of various platforms.
Planned are client implementations for the JVM as well as directly executable
machine code clients for various PC architectures. Additionally, a working
Javascript client should be established because of the cross compilation issue.

\subsection{Javascript client}

There are two approaches in implementing a Javascript client: The first
approach is by cross compiling the backend language into Javascript. There
is a well-maintained compiler for this purpose, but arbitrary size integers
have to be implemented there as well. The other approach is by writing
an entirely new client in vanilla Javascript. An advantage of a pure JS
client would be that the Javascript community has access to a clean
implementation of the duse technology stack.

\subsection{JVM-based client}

The JVM is available on lots of different architectures and offers a good 
abstraction on which many languages build. Some mentionable languages here are
of course Java, Scala and Clojure. These languages are bytecode compatible,
a single implementation here could be used across several JVM based languages.
As such, the JVM offers a broad developer community in which duse should
integrate in order for better adaption as well as a better availability of
clients. A difficulty of JVM based languages is the final packaging of the
executable software for different operating systems because of the dependency
on a specific JVM. Hence, a client in machine code should also exist.

\subsection{Machine code client}

Machine code clients have several advantages: They are easy to ship (compile
once per OS and underlying architecture) and usually performing rapidly.
Languages for this use case are for example C, Go, Rust and Nim.

\section{Mark as insecure}
\section{Expiry date}

\section{Hybrid encryption}

Hybrid encryption is known as the combination of asymmetric encryption and
symmentric encrypiton. First the plaintext is encrypted with a symmetric
encryption algorithm with a preferably randomly generated key. The used key is
then encrypted with the asymmetric public key algorithm. Hybrid encrypiton
eliminates some of the drawbacks for both kinds of algorithms.

For symmetric encryption the soundness relies on the randomness of the key
used. If the key is not random, then there is no point in using it. If the key,
however, is random and complex, then it is very well suited. The problem with
random and complex keys is, that they are hard to remember for humans.
Therefore the key is encrypted with the public key of a user, who can encrypt
it due to the ownership of the private key.

Not only does this have an effect on the usability for humans, but it also
softens restrictions of the two mechanisms. A restriction of asymmetric
encryption is the limited plaintext size. Symmetric encryption does not have
any limit on the plaintext size, and is significantly more performant.
Therefore combining the who algorithms allows these restrictions to be
eliminated.

Integrating hybrid encryption into the duse protocol would require the secret
to save to be encrypted with symmetric encryption using a randomly generated
key. The key is then divided using Shamir's Secret Sharing and each share is
then encrypted with the participating users public keys.

\subsection{Advantages}

Introducing hybrid encryption would improve multiple aspects of the overall
system. In the following paragraphs, the most notable ones are depicted.

\paragraph{Less asymmetric crypto}{ In comparison to the mechanism developed in
  \ref{sec:duse:crypto_protocol}, this only requires asymmetric encryption to
  be used once per user, instead of once per user per secret part. Additionally
  it allows large secrets to be saved more efficiently, since the decryption of
the symmetric cipher texts is very performant. Requireing thousands of
decryption processes is not feasible, in contrast to a single performant
decryption.}

\paragraph{Less complex storage}{ Not only does this mechanism reduce the load
  on clients, but also on the server. The server decrypts its own share of the
  symmetric key only once instead of $n$ times, where $n$ is the number of
  parts of a secret.  Having many parts, which in turn also have many shares is
complex to safe. A single large cipher text is easier to handle. If the upper
limits of a data type of the used database is not large enough, the cipher
texts could be safed in a distributed filesystem.}

\paragraph{Less complex, more efficient Validation}{ Besides the improved
  storage possibilities on a low level, the complexity of the associations is
  also reduced. Instead of each part containing shares, a secret only has one
  set of shares.  Therefore the semantic validation also becomes less complex,
  since relationships between parts do not have to be verified. When using the
  parts attempt, the server has to verify, that all users the shares assiociate
  to have to be the same for all parts. Apart from that, each shares signature
  is checked, which is a slow operation. An attacker could use this
characteristic to perform a denial of service attack. Using the hybrid
encryption approach minimizes the signature checks to the number of
participants. }

\paragraph{Detailed updates}{ Separating cipher and access allows updating a
  secret to be performed in a more detailed manner. The cipher text must only
  be modified, if the plaintext it conceals is changed. If the participating
  parties are modified only the shares are changed. Hence, the API can
differentiate what part of the secret is changed and can log the type of
change, as well as have named rollbacks when using a revisioning mechanism. }
